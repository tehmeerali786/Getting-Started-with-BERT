{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Getting Started with BERT Chapter 6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhfXchi3EQW6"
      },
      "source": [
        "# **Training the BERTSUM Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuQNMiCRCxx6",
        "outputId": "5d02d8d1-b46e-420c-89a0-3214b44168a8"
      },
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "!pip install torch==1.1.0 pytorch_transformers tensorboardX multiprocess pyrouge\n",
        "!pip install googleDriveFileDownloader\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 28.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 25.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 28.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 26.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 29.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 17.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 18.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 18.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 18.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 18.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 18.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 18.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/a3/388f78a63b0545f30daf13e6542b0d850f621ff51ef721cf431eef609c87/boto3-1.17.59-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 37.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.8.1+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.21.0,>=1.20.59\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/68/e91883d8f68183216fac7cfa855cd0d1b3336c3d4b82cd4b99591118bcc7/botocore-1.20.59-py2.py3-none-any.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 54.6MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.5.0,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/d0/693477c688348654ddc21dcdce0817653a294aa43f41771084c25e7ff9c7/s3transfer-0.4.2-py2.py3-none-any.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.59->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.59->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.20.59 has requirement urllib3<1.27,>=1.25.4, but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.17.59 botocore-1.20.59 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.4.2\n",
            "Collecting torch==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/23/a4b5c189dd624411ec84613b717594a00480282b949e3448d189c4aa4e47/torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9MB)\n",
            "\u001b[K     |████████████████████████████████| 676.9MB 26kB/s \n",
            "\u001b[?25hCollecting pytorch_transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 50.5MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/84/46421bd3e0e89a92682b1a38b40efc22dafb6d8e3d947e4ceefd4a5fabc7/tensorboardX-2.2-py2.py3-none-any.whl (120kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 62.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (0.70.11.1)\n",
            "Collecting pyrouge\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/85/e522dd6b36880ca19dcf7f262b22365748f56edc6f455e7b6a37d0382c32/pyrouge-0.1.3.tar.gz (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.1.0) (1.19.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 44.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 55.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (1.17.59)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_transformers) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: dill>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from multiprocess) (0.3.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch_transformers) (7.1.2)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.59 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (1.20.59)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_transformers) (0.4.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_transformers) (2.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (56.0.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.59->boto3->pytorch_transformers) (2.8.1)\n",
            "Building wheels for collected packages: pyrouge\n",
            "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyrouge: filename=pyrouge-0.1.3-cp37-none-any.whl size=191613 sha256=c4be09ae4a7b7df19cfe017484eafce65f76850e7e6cf8c4347233c988b2c154\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/d3/0c/e5b04e15b6b87c42e980de3931d2686e14d36e045058983599\n",
            "Successfully built pyrouge\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, sacremoses, sentencepiece, pytorch-transformers, tensorboardX, pyrouge\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed pyrouge-0.1.3 pytorch-transformers-1.2.0 sacremoses-0.0.45 sentencepiece-0.1.95 tensorboardX-2.2 torch-1.1.0\n",
            "Collecting googleDriveFileDownloader\n",
            "  Downloading https://files.pythonhosted.org/packages/7a/b8/153f2082103ae57cc871575b5acedb7dd87deed4e751c174af62a2c732b9/googleDriveFileDownloader-1.2-py3-none-any.whl\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from googleDriveFileDownloader) (4.6.3)\n",
            "Installing collected packages: googleDriveFileDownloader\n",
            "Successfully installed googleDriveFileDownloader-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YB3Fv9MZEvzM"
      },
      "source": [
        "!cd /content/"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOEcWhPyFuqB",
        "outputId": "300d7628-c2a4-45f9-a2b2-5ef0ee8af2c9"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOgVFzxAFu85"
      },
      "source": [
        "### **Clone BERTSUM Repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX2_IUn-Fgwi",
        "outputId": "4aa4066c-1cc5-49fb-c866-242730a28050"
      },
      "source": [
        "!git clone  https://github.com/nlpyang/BertSum.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BertSum'...\n",
            "remote: Enumerating objects: 301, done.\u001b[K\n",
            "remote: Total 301 (delta 0), reused 0 (delta 0), pack-reused 301\u001b[K\n",
            "Receiving objects: 100% (301/301), 15.03 MiB | 21.47 MiB/s, done.\n",
            "Resolving deltas: 100% (174/174), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boN8eajUF3NO"
      },
      "source": [
        "### **Now switch to the bert_data directory**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJnkJy17FoUO",
        "outputId": "728a7da8-8231-4c21-89c3-80a91a764f13"
      },
      "source": [
        "cd /content/BertSum/bert_data/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BertSum/bert_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWs6UUWOJzBA",
        "outputId": "2969cb64-e86e-4935-a342-54b0b57c563d"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BertSum/bert_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfT6S28vGMUu"
      },
      "source": [
        "### **CNN/Daily Mail News Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT6a8_FtGIaP",
        "outputId": "1cf2a2a8-cd9d-4f33-fcac-018c5317e901"
      },
      "source": [
        "from googleDriveFileDownloader import googleDriveFileDownloader\n",
        "gdrive = googleDriveFileDownloader()\n",
        "gdrive.downloadFile(\"https://drive.google.com/uc?id=1x0d61LP9UAN389YN00z0Pv-7jQgirVg6&export=download\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download is starting\n",
            "FILENAME ::: bertsum_data.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9QxDRDlJffY",
        "outputId": "1ae5e7ea-d0a2-4ba4-adc6-174976950712"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bertsum_data.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FetLqKbeJt-I",
        "outputId": "bfbe0a95-a3b2-4b57-9c8a-bd6f73c4800d"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BertSum/bert_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "247g4cCEItYz"
      },
      "source": [
        "### **Unzip downloaded data set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMBYbIh5I05q",
        "outputId": "e0e71da1-a7cf-453b-f1ac-712c6c245324"
      },
      "source": [
        "!unzip /content/BertSum/bert_data/bertsum_data.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/BertSum/bert_data/bertsum_data.zip\n",
            "  inflating: cnndm.test.0.bert.pt    \n",
            "  inflating: cnndm.test.1.bert.pt    \n",
            "  inflating: cnndm.test.2.bert.pt    \n",
            "  inflating: cnndm.test.3.bert.pt    \n",
            "  inflating: cnndm.test.4.bert.pt    \n",
            "  inflating: cnndm.test.5.bert.pt    \n",
            "  inflating: cnndm.train.0.bert.pt   \n",
            "  inflating: cnndm.train.100.bert.pt  \n",
            "  inflating: cnndm.train.101.bert.pt  \n",
            "  inflating: cnndm.train.102.bert.pt  \n",
            "  inflating: cnndm.train.103.bert.pt  \n",
            "  inflating: cnndm.train.104.bert.pt  \n",
            "  inflating: cnndm.train.105.bert.pt  \n",
            "  inflating: cnndm.train.106.bert.pt  \n",
            "  inflating: cnndm.train.107.bert.pt  \n",
            "  inflating: cnndm.train.108.bert.pt  \n",
            "  inflating: cnndm.train.109.bert.pt  \n",
            "  inflating: cnndm.train.10.bert.pt  \n",
            "  inflating: cnndm.train.110.bert.pt  \n",
            "  inflating: cnndm.train.111.bert.pt  \n",
            "  inflating: cnndm.train.112.bert.pt  \n",
            "  inflating: cnndm.train.113.bert.pt  \n",
            "  inflating: cnndm.train.114.bert.pt  \n",
            "  inflating: cnndm.train.115.bert.pt  \n",
            "  inflating: cnndm.train.116.bert.pt  \n",
            "  inflating: cnndm.train.117.bert.pt  \n",
            "  inflating: cnndm.train.118.bert.pt  \n",
            "  inflating: cnndm.train.119.bert.pt  \n",
            "  inflating: cnndm.train.11.bert.pt  \n",
            "  inflating: cnndm.train.120.bert.pt  \n",
            "  inflating: cnndm.train.121.bert.pt  \n",
            "  inflating: cnndm.train.122.bert.pt  \n",
            "  inflating: cnndm.train.123.bert.pt  \n",
            "  inflating: cnndm.train.124.bert.pt  \n",
            "  inflating: cnndm.train.125.bert.pt  \n",
            "  inflating: cnndm.train.126.bert.pt  \n",
            "  inflating: cnndm.train.127.bert.pt  \n",
            "  inflating: cnndm.train.128.bert.pt  \n",
            "  inflating: cnndm.train.129.bert.pt  \n",
            "  inflating: cnndm.train.12.bert.pt  \n",
            "  inflating: cnndm.train.130.bert.pt  \n",
            "  inflating: cnndm.train.131.bert.pt  \n",
            "  inflating: cnndm.train.132.bert.pt  \n",
            "  inflating: cnndm.train.133.bert.pt  \n",
            "  inflating: cnndm.train.134.bert.pt  \n",
            "  inflating: cnndm.train.135.bert.pt  \n",
            "  inflating: cnndm.train.136.bert.pt  \n",
            "  inflating: cnndm.train.137.bert.pt  \n",
            "  inflating: cnndm.train.138.bert.pt  \n",
            "  inflating: cnndm.train.139.bert.pt  \n",
            "  inflating: cnndm.train.13.bert.pt  \n",
            "  inflating: cnndm.train.140.bert.pt  \n",
            "  inflating: cnndm.train.141.bert.pt  \n",
            "  inflating: cnndm.train.142.bert.pt  \n",
            "  inflating: cnndm.train.143.bert.pt  \n",
            "  inflating: cnndm.train.14.bert.pt  \n",
            "  inflating: cnndm.train.15.bert.pt  \n",
            "  inflating: cnndm.train.16.bert.pt  \n",
            "  inflating: cnndm.train.17.bert.pt  \n",
            "  inflating: cnndm.train.18.bert.pt  \n",
            "  inflating: cnndm.train.19.bert.pt  \n",
            "  inflating: cnndm.train.1.bert.pt   \n",
            "  inflating: cnndm.train.20.bert.pt  \n",
            "  inflating: cnndm.train.21.bert.pt  \n",
            "  inflating: cnndm.train.22.bert.pt  \n",
            "  inflating: cnndm.train.23.bert.pt  \n",
            "  inflating: cnndm.train.24.bert.pt  \n",
            "  inflating: cnndm.train.25.bert.pt  \n",
            "  inflating: cnndm.train.26.bert.pt  \n",
            "  inflating: cnndm.train.27.bert.pt  \n",
            "  inflating: cnndm.train.28.bert.pt  \n",
            "  inflating: cnndm.train.29.bert.pt  \n",
            "  inflating: cnndm.train.2.bert.pt   \n",
            "  inflating: cnndm.train.30.bert.pt  \n",
            "  inflating: cnndm.train.31.bert.pt  \n",
            "  inflating: cnndm.train.32.bert.pt  \n",
            "  inflating: cnndm.train.33.bert.pt  \n",
            "  inflating: cnndm.train.34.bert.pt  \n",
            "  inflating: cnndm.train.35.bert.pt  \n",
            "  inflating: cnndm.train.36.bert.pt  \n",
            "  inflating: cnndm.train.37.bert.pt  \n",
            "  inflating: cnndm.train.38.bert.pt  \n",
            "  inflating: cnndm.train.39.bert.pt  \n",
            "  inflating: cnndm.train.3.bert.pt   \n",
            "  inflating: cnndm.train.40.bert.pt  \n",
            "  inflating: cnndm.train.41.bert.pt  \n",
            "  inflating: cnndm.train.42.bert.pt  \n",
            "  inflating: cnndm.train.43.bert.pt  \n",
            "  inflating: cnndm.train.44.bert.pt  \n",
            "  inflating: cnndm.train.45.bert.pt  \n",
            "  inflating: cnndm.train.46.bert.pt  \n",
            "  inflating: cnndm.train.47.bert.pt  \n",
            "  inflating: cnndm.train.48.bert.pt  \n",
            "  inflating: cnndm.train.49.bert.pt  \n",
            "  inflating: cnndm.train.4.bert.pt   \n",
            "  inflating: cnndm.train.50.bert.pt  \n",
            "  inflating: cnndm.train.51.bert.pt  \n",
            "  inflating: cnndm.train.52.bert.pt  \n",
            "  inflating: cnndm.train.53.bert.pt  \n",
            "  inflating: cnndm.train.54.bert.pt  \n",
            "  inflating: cnndm.train.55.bert.pt  \n",
            "  inflating: cnndm.train.56.bert.pt  \n",
            "  inflating: cnndm.train.57.bert.pt  \n",
            "  inflating: cnndm.train.58.bert.pt  \n",
            "  inflating: cnndm.train.59.bert.pt  \n",
            "  inflating: cnndm.train.5.bert.pt   \n",
            "  inflating: cnndm.train.60.bert.pt  \n",
            "  inflating: cnndm.train.61.bert.pt  \n",
            "  inflating: cnndm.train.62.bert.pt  \n",
            "  inflating: cnndm.train.63.bert.pt  \n",
            "  inflating: cnndm.train.64.bert.pt  \n",
            "  inflating: cnndm.train.65.bert.pt  \n",
            "  inflating: cnndm.train.66.bert.pt  \n",
            "  inflating: cnndm.train.67.bert.pt  \n",
            "  inflating: cnndm.train.68.bert.pt  \n",
            "  inflating: cnndm.train.69.bert.pt  \n",
            "  inflating: cnndm.train.6.bert.pt   \n",
            "  inflating: cnndm.train.70.bert.pt  \n",
            "  inflating: cnndm.train.71.bert.pt  \n",
            "  inflating: cnndm.train.72.bert.pt  \n",
            "  inflating: cnndm.train.73.bert.pt  \n",
            "  inflating: cnndm.train.74.bert.pt  \n",
            "  inflating: cnndm.train.75.bert.pt  \n",
            "  inflating: cnndm.train.76.bert.pt  \n",
            "  inflating: cnndm.train.77.bert.pt  \n",
            "  inflating: cnndm.train.78.bert.pt  \n",
            "  inflating: cnndm.train.79.bert.pt  \n",
            "  inflating: cnndm.train.7.bert.pt   \n",
            "  inflating: cnndm.train.80.bert.pt  \n",
            "  inflating: cnndm.train.81.bert.pt  \n",
            "  inflating: cnndm.train.82.bert.pt  \n",
            "  inflating: cnndm.train.83.bert.pt  \n",
            "  inflating: cnndm.train.84.bert.pt  \n",
            "  inflating: cnndm.train.85.bert.pt  \n",
            "  inflating: cnndm.train.86.bert.pt  \n",
            "  inflating: cnndm.train.87.bert.pt  \n",
            "  inflating: cnndm.train.88.bert.pt  \n",
            "  inflating: cnndm.train.89.bert.pt  \n",
            "  inflating: cnndm.train.8.bert.pt   \n",
            "  inflating: cnndm.train.90.bert.pt  \n",
            "  inflating: cnndm.train.91.bert.pt  \n",
            "  inflating: cnndm.train.92.bert.pt  \n",
            "  inflating: cnndm.train.93.bert.pt  \n",
            "  inflating: cnndm.train.94.bert.pt  \n",
            "  inflating: cnndm.train.95.bert.pt  \n",
            "  inflating: cnndm.train.96.bert.pt  \n",
            "  inflating: cnndm.train.97.bert.pt  \n",
            "  inflating: cnndm.train.98.bert.pt  \n",
            "  inflating: cnndm.train.99.bert.pt  \n",
            "  inflating: cnndm.train.9.bert.pt   \n",
            "  inflating: cnndm.valid.0.bert.pt   \n",
            "  inflating: cnndm.valid.1.bert.pt   \n",
            "  inflating: cnndm.valid.2.bert.pt   \n",
            "  inflating: cnndm.valid.3.bert.pt   \n",
            "  inflating: cnndm.valid.4.bert.pt   \n",
            "  inflating: cnndm.valid.5.bert.pt   \n",
            "  inflating: cnndm.valid.6.bert.pt   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjqqJ6V1LWqm",
        "outputId": "ffcb357a-2372-4cfa-f9f6-7c452cb228f3"
      },
      "source": [
        "cd /content/BertSum/src"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/BertSum/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX2wR-t2G1ZO"
      },
      "source": [
        "### **Now train the BERTSUM model. In the following code, the argument -encoder classifier impliess that we are training the BERTSUM model with a classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImSkPgdqGl58",
        "outputId": "8d7f5ba6-97ab-401f-cd96-c85a59f55095"
      },
      "source": [
        "!python train.py -mode train -encoder classifier -dropout 0.1 -bert_data_path ../bert_data/cnndm -model_path ../models/bert_classifier -lr 2e-3 -visible_gpus 0 -gpu_ranks 0 -world_size 1 -report_every 50 -save_checkpoint_steps 1000 -batch_size 3000 -decay_method noam -train_steps 50 -accum_count 2 -log_file ../logs/bert_classifier -use_interval true -warmup_steps 10000"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-04-28 01:53:44,886 INFO] Device ID 0\n",
            "[2021-04-28 01:53:44,887 INFO] Device cuda\n",
            "[2021-04-28 01:53:45,083 INFO] https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmp7082m_6g\n",
            "100% 407873900/407873900 [00:06<00:00, 66795626.02B/s]\n",
            "[2021-04-28 01:53:51,304 INFO] copying /tmp/tmp7082m_6g to cache at ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "[2021-04-28 01:53:52,509 INFO] creating metadata file for ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "[2021-04-28 01:53:52,509 INFO] removing temp file /tmp/tmp7082m_6g\n",
            "[2021-04-28 01:53:52,559 INFO] loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "[2021-04-28 01:53:52,559 INFO] extracting archive file ../temp/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmphwfsnzck\n",
            "[2021-04-28 01:53:56,230 INFO] Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[2021-04-28 01:54:06,908 INFO] Summarizer(\n",
            "  (bert): Bert(\n",
            "    (model): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): BertLayerNorm()\n",
            "        (dropout): Dropout(p=0.1)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): Classifier(\n",
            "    (linear1): Linear(in_features=768, out_features=1, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            ")\n",
            "gpu_rank 0\n",
            "[2021-04-28 01:54:06,920 INFO] * number of parameters: 109483009\n",
            "[2021-04-28 01:54:06,920 INFO] Start training...\n",
            "[2021-04-28 01:54:07,011 INFO] Loading train dataset from ../bert_data/cnndm.train.123.bert.pt, number of examples: 2001\n",
            "[2021-04-28 01:55:04,779 INFO] Step 50/   50; xent: 7.34; lr: 0.0000001;  17 docs/s;     58 sec\n",
            "[2021-04-28 01:55:04,882 INFO] Loading train dataset from ../bert_data/cnndm.train.140.bert.pt, number of examples: 2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzV1BBpHIiUk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}